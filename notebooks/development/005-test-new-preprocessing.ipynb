{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from climatetranslation.unit.data import get_all_data_loaders, CustomTransformer\n",
    "from climatetranslation.unit.utils import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_save_iter': 10000,\n",
       " 'image_display_iter': 100,\n",
       " 'display_size': 16,\n",
       " 'snapshot_save_iter': 10000,\n",
       " 'log_iter': 10,\n",
       " 'max_iter': 1000000,\n",
       " 'batch_size': 1,\n",
       " 'weight_decay': 0.0001,\n",
       " 'beta1': 0.5,\n",
       " 'beta2': 0.999,\n",
       " 'init': 'kaiming',\n",
       " 'lr': 0.0001,\n",
       " 'lr_policy': 'step',\n",
       " 'step_size': 100000,\n",
       " 'gamma': 0.5,\n",
       " 'gan_w': 4,\n",
       " 'recon_x_w': 10,\n",
       " 'recon_h_w': 0,\n",
       " 'recon_kl_w': 0.01,\n",
       " 'recon_x_cyc_w': 10,\n",
       " 'recon_kl_cyc_w': 0.01,\n",
       " 'vgg_w': 0,\n",
       " 'gen': {'dim': 64,\n",
       "  'mlp_dim': 256,\n",
       "  'style_dim': 8,\n",
       "  'activ': 'relu',\n",
       "  'n_downsample': 2,\n",
       "  'n_res': 4,\n",
       "  'pad_type': 'zero',\n",
       "  'upsample': 'bilinear',\n",
       "  'output_activ': ['relu', 'none', 'none', 'none']},\n",
       " 'dis': {'dim': 64,\n",
       "  'norm': 'none',\n",
       "  'activ': 'lrelu',\n",
       "  'n_layer': 4,\n",
       "  'gan_type': 'lsgan',\n",
       "  'num_scales': 3,\n",
       "  'pad_type': 'reflect'},\n",
       " 'num_workers': 5,\n",
       " 'data_zarr_a': '/datadrive/hadgem3/nat_hist_zarr',\n",
       " 'data_zarr_b': '/datadrive/cam5/nat_hist_zarr',\n",
       " 'agg_data_a': '/datadrive/hadgem3/nat_hist_agg.nc',\n",
       " 'agg_data_b': '/datadrive/cam5/nat_hist_agg.nc',\n",
       " 'preprocess_method': 'custom_nofield',\n",
       " 'test_size': 0.2,\n",
       " 'level_vars': {0: ['pr'], 2: ['tas', 'tasmin', 'tasmax']}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = get_config(\"/home/dfulu/model_outputs/outputs/hadgem3_to_cam5_nat-hist-v6/config.yaml\")\n",
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for reasonable looking results when loaded\n",
    "- [x] units\n",
    "- [x] zeromean\n",
    "- [x] normalise\n",
    "- [x] custom_nofield\n",
    "- [x] custom_allfield\n",
    "- [x] custom_tasfield\n",
    "- [ ] custom_prfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_nofield\n"
     ]
    }
   ],
   "source": [
    "# units\n",
    "#conf['preprocess_method'] = 'custom_nofield' # [units, zeromean, normalise, custom_nofield, custom_allfield, custom_tasfield, custom_prfield]\n",
    "print(conf['preprocess_method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'split_at'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7402fade6209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_data_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dfulu/repos/climateTranslation/climatetranslation/unit/data.py\u001b[0m in \u001b[0;36mget_all_data_loaders\u001b[0;34m(conf)\u001b[0m\n\u001b[1;32m    485\u001b[0m               'num_workers': conf['num_workers']}\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m     \u001b[0mds_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_zarr_a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level_vars'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split_at'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0mds_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_zarr_b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level_vars'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split_at'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'split_at'"
     ]
    }
   ],
   "source": [
    "loaders = get_all_data_loaders(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at individual samples of preprocessed data and the time means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders[0].dataset.ds.lat.shape, loaders[2].dataset.ds.lat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "loaders[0].dataset.ds.tas.isel(run=0, time=0).plot()\n",
    "plt.title(f\"train dataset {conf['data_zarr_a']}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "ds = loaders[2].dataset.ds.tas.isel(run=0, time=0).plot()\n",
    "plt.title(f\"dataset {conf['data_zarr_b']} train\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = loaders[2].dataset.ds.isel(run=0, time=slice(0, 700, 11)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "(ds.tas.isel(time=0)+70).plot(norm=colors.LogNorm())\n",
    "plt.subplot(122)\n",
    "ds.tas.isel(time=0).plot(norm=colors.Normalize(vmin=-5, vmax=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the temperature above data, processed as Temp_K$_{ij}$ -> (Temp_K$_{ij}$ -273.15)/$\\sigma_{ij}$, it looks like a bad transform. However, you have to remember that the network will be looking for differences between the predicted and real values. The real values have unit variance even if the means are very different. This method of preprocessing means 0 degress Celcius is given a value of 0 after preprocessing globally and stops the poles, which have higher variance, dominating the errors.\n",
    "\n",
    "On the other hand, the convolutional filters may have some trouble dealing with how spatially inhomogeneous the transform makes this. So either of `custom_tasfield` or `custom_nofield` could be best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "ds.pr.isel(time=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.pr.mean(dim='time').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.pr.std(dim='time').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tas.std(dim='time').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for ability to translate back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units\n",
    "#conf['preprocess_method'] = 'custom_tasfield' # [units, zeromean, normalise, custom_nofield, custom_allfield, custom_tasfield, custom_prfield]\n",
    "#loaders = get_all_data_loaders(conf)\n",
    "\n",
    "if conf['preprocess_method']=='zeromean':\n",
    "    trans = ZeroMeaniser(conf, downscale_consolidate=True)\n",
    "elif conf['preprocess_method']=='normalise':\n",
    "    trans = Normaliser(conf, downscale_consolidate=True)\n",
    "elif conf['preprocess_method']=='units':\n",
    "    trans = UnitModifier(conf, downscale_consolidate=True)\n",
    "elif conf['preprocess_method']=='custom_allfield':\n",
    "    trans = CustomTransformer(conf, downscale_consolidate=True, tas_field_norm=True, pr_field_norm=True)\n",
    "elif conf['preprocess_method']=='custom_tasfield':\n",
    "    trans = CustomTransformer(conf, downscale_consolidate=True, tas_field_norm=True, pr_field_norm=False)\n",
    "elif conf['preprocess_method']=='custom_prfield':\n",
    "    trans = CustomTransformer(conf, downscale_consolidate=True, tas_field_norm=False, pr_field_norm=True)\n",
    "elif conf['preprocess_method']=='custom_nofield':\n",
    "    trans = CustomTransformer(conf, downscale_consolidate=True, tas_field_norm=False, pr_field_norm=False)\n",
    "else:\n",
    "    raise ValueError(f\"Unrecognised preprocess_method : {conf['preprocess_method']}\")\n",
    "\n",
    "ds_a = loaders[0].dataset.ds.isel(time=1, run=0).compute()\n",
    "ds_b = loaders[2].dataset.ds.isel(time=1, run=0).compute()\n",
    "    \n",
    "trans.fit(trans.ds_agg_a, trans.ds_agg_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed data\n",
    "plt.figure(figsize=(24,10))\n",
    "ax = plt.subplot(121)\n",
    "ds_a.tas.plot(ax=ax)\n",
    "ax = plt.subplot(122)\n",
    "ds_b.tas.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de-processed data\n",
    "trans.inverse_a(ds_a).tas.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "xr.open_zarr(conf['data_zarr_a']).isel(time=1, run=0, height=1).tas.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test full train loading scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from climatetranslation.unit.utils import prepare_sub_folder, write_html, write_loss, get_config, write_2images, Timer\n",
    "from climatetranslation.unit.data import get_all_data_loaders\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import tensorboardX\n",
    "\n",
    "\n",
    "# replace the argparser in original\n",
    "class blank:\n",
    "    pass\n",
    "\n",
    "opts = blank()\n",
    "opts.config = '/home/dfulu//repos/climateTranslation/climatetranslation/unit/configs/hadgem3_to_cam5_nat-hist-v6.yaml'\n",
    "opts.output_path = '/home/dfulu/tmp'\n",
    "opts.resume = False\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Load experiment setting\n",
    "config = get_config(opts.config)\n",
    "\n",
    "display_size = 2 # config['display_size']\n",
    "config['batch_size'] = 2\n",
    "#config['preprocess_method'] = 'custom_nofield' # works : 'normalise', 'units' no-works: 'custom_allfield'\n",
    "\n",
    "# data loaders\n",
    "train_loader_a, test_loader_a, train_loader_b, test_loader_b = get_all_data_loaders(config, downscale_consolidate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of climate fields to display after a number of updates\n",
    "def generate_n(generator, n):\n",
    "    return torch.cat([img for _, img in zip(range((n-1)//generator.batch_size + 1), generator)])[:n]\n",
    "\n",
    "def generate_batch(generator, *args):\n",
    "    return [img for _, img in zip(range(1), generator)][0]\n",
    "\n",
    "train_display_images_a = generate_batch(train_loader_a, display_size)#.cuda()\n",
    "train_display_images_b = generate_batch(train_loader_b, display_size)#.cuda()\n",
    "test_display_images_a  = generate_batch(test_loader_a, display_size)#.cuda()\n",
    "test_display_images_b  = generate_batch(test_loader_b, display_size)#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine(imgs):\n",
    "    return torch.isnan(imgs).any().item(), imgs.max().item(), imgs.min().item()\n",
    "\n",
    "print('set    ', 'isnan, max, min')\n",
    "print('train a', examine(train_display_images_a))\n",
    "print('train b', examine(train_display_images_b))\n",
    "print('test  a', examine(test_display_images_a))\n",
    "print('test  b', examine(test_display_images_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(24,8))\n",
    "image_outputs = [images[:,:3].expand(-1, 3, -1, -1) for images in [train_display_images_a, train_display_images_b]]\n",
    "image_tensor = torch.cat([images[:display_size] for images in image_outputs], 0)\n",
    "image_grid = vutils.make_grid(image_tensor.data, nrow=config['batch_size'], padding=0, normalize=True)\n",
    "plt.imshow(image_grid.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A small amount of datetimes have all NaN data\n",
    "def all_nan_last_two_axis_any_channel(x):\n",
    "    #return torch.any(torch.all(torch.all(torch.isnan(x), axis=-1), axis=-1), axis=-1)\n",
    "    return torch.isnan(x).all(dim=-1).all(dim=-1).any()\n",
    "\n",
    "# Start training\n",
    "iterations = trainer.resume(checkpoint_directory, hyperparameters=config) if opts.resume else 0\n",
    "\n",
    "\n",
    "for it, (images_a, images_b) in enumerate(zip(train_loader_a, train_loader_b)):\n",
    "    # Skip NaN fields\n",
    "    if all_nan_last_two_axis_any_channel(images_a) or all_nan_last_two_axis_any_channel(images_b):\n",
    "        print('Skipped on it = {}'.format(it))\n",
    "        continue\n",
    "\n",
    "    images_a, images_b = images_a.cuda().detach(), images_b.cuda().detach()\n",
    "    break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_a.shape, images_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(24,8))\n",
    "image_outputs = [images[:,:3].cpu().expand(-1, 3, -1, -1) for images in [images_a, images_b]]\n",
    "image_tensor = torch.cat([images for images in image_outputs], 0)\n",
    "image_grid = vutils.make_grid(image_tensor.data, nrow=config['batch_size'], padding=0, normalize=True)\n",
    "plt.imshow(image_grid.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../../climatetranslation/unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -l /home/dfulu/model_outputs/outputs/hadgem3_to_cam5_nat-hist-v6/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "\n",
    "hv.extension('bokeh')\n",
    "\n",
    "from translate import network_translate_constructor\n",
    "from utils import get_config\n",
    "from data import (get_dataset, \n",
    "                  CustomTransformer, \n",
    "                  UnitModifier, \n",
    "                  ZeroMeaniser, \n",
    "                  Normaliser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stand in for arg-parser\n",
    "class argsob:\n",
    "    pass\n",
    "\n",
    "def get_translation(args):\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "    # Load experiment setting\n",
    "    config = get_config(args.config)\n",
    "    config['gen']['upsample']='nearest'\n",
    "\n",
    "    # load the datasets\n",
    "    ds_a = get_dataset(config['data_zarr_a'], config['level_vars'])\n",
    "    ds_b = get_dataset(config['data_zarr_b'], config['level_vars'])\n",
    "\n",
    "    # load pre/post processing transformer\n",
    "    if config['preprocess_method']=='zeromean':\n",
    "        prepost_trans = ZeroMeaniser(config, downscale_consolidate=True)\n",
    "    elif config['preprocess_method']=='normalise':\n",
    "        prepost_trans = Normaliser(config, downscale_consolidate=True)\n",
    "    elif config['preprocess_method']=='units':\n",
    "        prepost_trans = UnitModifier(config, downscale_consolidate=True)\n",
    "    elif config['preprocess_method']=='custom_allfield':\n",
    "        prepost_trans = CustomTransformer(config, downscale_consolidate=True, tas_field_norm=True, pr_field_norm=True)\n",
    "    elif config['preprocess_method']=='custom_tasfield':\n",
    "        prepost_trans = CustomTransformer(config, downscale_consolidate=True, tas_field_norm=True, pr_field_norm=False)\n",
    "    elif config['preprocess_method']=='custom_prfield':\n",
    "        prepost_trans = CustomTransformer(config, downscale_consolidate=True, tas_field_norm=False, pr_field_norm=True)\n",
    "    elif config['preprocess_method']=='custom_nofield':\n",
    "        prepost_trans = CustomTransformer(config, downscale_consolidate=True, tas_field_norm=False, pr_field_norm=False)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognised preprocess_method : {conf['preprocess_method']}\")\n",
    "    prepost_trans.fit(ds_a, ds_b)\n",
    "\n",
    "    pre_trans = prepost_trans.transform_a if args.x2x[0]=='a' else prepost_trans.transform_b\n",
    "    post_trans = prepost_trans.inverse_a if args.x2x[-1]=='a' else prepost_trans.inverse_b\n",
    "\n",
    "    # load model \n",
    "    config['input_dim_a'] = len(ds_a.keys())\n",
    "    config['input_dim_b'] = len(ds_b.keys())\n",
    "    net_trans = network_translate_constructor(config, args.checkpoint, args.x2x)\n",
    "\n",
    "    ds = ds_a if args.x2x[0]=='a' else ds_b    \n",
    "\n",
    "    n_times=100\n",
    "    ds_sample = ds.isel(time=slice(0, 11*n_times, 11), run=slice(0,1))\n",
    "\n",
    "    # pre-rocess and convert to array\n",
    "    da_pre = (\n",
    "        pre_trans(ds_sample)\n",
    "        .to_array()\n",
    "        .transpose('run', 'time', 'variable', 'lat', 'lon')\n",
    "    )\n",
    "\n",
    "    # transform through network \n",
    "    da_post = xr.apply_ufunc(\n",
    "        net_trans, \n",
    "        da_pre,\n",
    "        vectorize=True,\n",
    "        dask='allowed',\n",
    "        output_dtypes=['float'],\n",
    "        input_core_dims=[['variable', 'lat', 'lon']],\n",
    "        output_core_dims=[['variable', 'lat', 'lon']]\n",
    "    )\n",
    "\n",
    "    # fix chunking\n",
    "    da_post = da_post.chunk(dict(run=1, time=1, lat=-1, lon=-1))\n",
    "\n",
    "    # post-process\n",
    "    ds_translated = post_trans(da_post.to_dataset(dim='variable')).compute()\n",
    "    \n",
    "    da_prepost = post_trans(da_pre.to_dataset(dim='variable')).compute()\n",
    "    \n",
    "    return ds_translated, da_prepost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2(tn, var='tas', vmin=None, vmax=None, **kwargs):\n",
    "    plt.figure(figsize=(12, 21))\n",
    "    plt.subplot(311)\n",
    "    if vmin is None:\n",
    "        vmin = min([\n",
    "            float(ds_translated_v5.isel(time=tn)[var].min()),\n",
    "            float(ds_translated_v6.isel(time=tn)[var].min()),\n",
    "            float(da_prepost.isel(time=tn)[var].min())\n",
    "        ])\n",
    "    if vmax is None:\n",
    "        vmax = max([\n",
    "            float(ds_translated_v5.isel(time=tn)[var].max()),\n",
    "            float(ds_translated_v6.isel(time=tn)[var].max()),\n",
    "            float(da_prepost.isel(time=tn)[var].max())\n",
    "        ])\n",
    "    \n",
    "    ds_translated_v5.isel(time=tn).sel(**kwargs)[var].plot(vmin=vmin, vmax=vmax)\n",
    "    plt.title(\"v5\")\n",
    "    plt.subplot(312)\n",
    "\n",
    "    ds_translated_v6.isel(time=tn).sel(**kwargs)[var].plot(vmin=vmin, vmax=vmax)\n",
    "    plt.title(\"v6\")\n",
    "    plt.subplot(313)\n",
    "\n",
    "    da_prepost.isel(time=tn).sel(**kwargs)[var].plot(vmin=vmin, vmax=vmax)\n",
    "    plt.title(\"pre then post\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�\u0002�\n",
      "\u0000\u0000\u0000little_endianq\u0002�Xq\u0000(X\u0010\u0000\u0000\u0000protocol_versionq\u0001M�\u0003X\n",
      "\u0000\u0000\u0000type_sizesq\u0003}q\u0004(X\u0005\u0000\u0000\u0000shortq\u0005K\u0002X\u0003\u0000\u0000\u0000intq\u0006K\u0004X\u0004\u0000\u0000\u0000longq\u0007K\u0004uu.�\u0002}q\u0000(X\u0001\u0000\u0000\u0000aq\u0001ccollections\n",
      "OrderedDict\n",
      "q\u0002)Rq\u0003(X\u0017\u0000\u0000\u0000enc.model.0.conv.weightq\u0004ctorch._utils\n",
      "_rebuild_tensor_v2\n",
      "q\u0005((X\u0007\u0000\u0000\u0000storageq\u0006ctorch\n",
      "FloatStorage\n",
      "q\u0007X\u000e\u0000\u0000\u000094301127180880X\u0006\u0000\u0000\u0000cuda:0q\tM\u00001Ntq\n",
      "tq\u000eRq\u000fX\u0015\u0000\u0000\u0000enc.model.0.conv.biasq\u0010h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300235451152q\u0011X\u0006\u0000\u0000\u0000cuda:0q\u0012K@Ntq\u0013QK\u0000K@�q\u0014K\u0001�q\u0015�h\u0002)Rq\u0016tq\u0017Rq\u0018X\u0017\u0000\u0000\u0000enc.model.1.conv.weightq\u0019h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300027945792q\u001aX\u0006\u0000\u0000\u0000cuda:0q\u001bJ\u0000\u0000\u0002\u0000Ntq\u001c",
      "QK\u0000(K�K@K\u0004K\u0004tq\u001d",
      "(M\u0000\u0004K\u0010K\u0004K\u0001tq\u001e",
      "�h\u0002)Rq\u001ftq Rq!X\u0015\u0000\u0000\u0000enc.model.1.conv.biasq\"h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300125215184q#X\u0006\u0000\u0000\u0000cuda:0q$K�Ntq%QK\u0000K��q&K\u0001�q'�h\u0002)Rq(tq)Rq*X\u0017\u0000\u0000\u0000enc.model.2.conv.weightq+h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300027946816q,X\u0006\u0000\u0000\u0000cuda:0q-J\u0000\u0000Ntq.QK\u0000(M\u0000\u0001K�K\u0004K\u0004tq/(MK\u0010K\u0004K\u0001tq0�h\u0002)Rq1tq2Rq3X\u0015\u0000\u0000\u0000enc.model.2.conv.biasq4h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300001134944q5X\u0006\u0000\u0000\u0000cuda:0q6M\u0000\u0001Ntq7QK\u0000M\u0000\u0001�q8K\u0001�q9�h\u0002)Rq:tq;Rq<X'\u0000\u0000\u0000enc.model.3.model.0.model.0.conv.weightq=h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300027967328q>X\u0006\u0000\u0000\u0000cuda:0q?J\u0000\u0000\t\u0000Ntq@QK\u0000(M\u0000\u0001M\u0000\u0001K\u0003K\u0003tqA(M\u0000\tK\tK\u0003K\u0001tqB�h\u0002)RqCtqDRqEX%\u0000\u0000\u0000enc.model.3.model.0.model.0.conv.biasqFh\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094301127153632qGX\u0006\u0000\u0000\u0000cuda:0qHM\u0000\u0001NtqIQK\u0000M\u0000\u0001�qJK\u0001�qK�h\u0002)RqLtqMRqNX'\u0000\u0000\u0000enc.model.3.model.0.model.1.conv.weightqOh\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300027973344qPX\u0006\u0000\u0000\u0000cuda:0qQJ\u0000\u0000\t\u0000NtqRQK\u0000(M\u0000\u0001M\u0000\u0001K\u0003K\u0003tqS(M\u0000\tK\tK\u0003K\u0001tqT�h\u0002)RqUtqVRqWX%\u0000\u0000\u0000enc.model.3.model.0.model.1.conv.biasqXh\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300027973440qYX\u0006\u0000\u0000\u0000cuda:0qZM\u0000\u0001Ntq[QK\u0000M\u0000\u0001�q\\K\u0001�q]�h\u0002)Rq^tq_Rq`X'\u0000\u0000\u0000enc.model.3.model.1.model.0.conv.weightqah\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094301127164672qbX\u0006\u0000\u0000\u0000cuda:0qcJ\u0000\u0000\t\u0000NtqdQK\u0000(M\u0000\u0001M\u0000\u0001K\u0003K\u0003tqe(M\u0000\tK\tK\u0003K\u0001tqf�h\u0002)RqgtqhRqiX%\u0000\u0000\u0000enc.model.3.model.1.model.0.conv.biasqjh\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094301127183888qkX\u0006\u0000\u0000\u0000cuda:0qlM\u0000\u0001NtqmQK\u0000M\u0000\u0001�qnK\u0001�qo�h\u0002)RqptqqRqrX'\u0000\u0000\u0000enc.model.3.model.1.model.1.conv.weightqsh\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094301127168000qtX\u0006\u0000\u0000\u0000cuda:0quJ\u0000\u0000\t\u0000NtqvQK\u0000(M\u0000\u0001M\u0000\u0001K\u0003K\u0003tqw(M\u0000\tK\tK\u0003K\u0001tqx�h\u0002)RqytqzRq{X%\u0000\u0000\u0000enc.model.3.model.1.model.1.conv.biasq|h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094301127173408q}X\u0006\u0000\u0000\u0000cuda:0q~M\u0000\u0001NtqQK\u0000M\u0000\u0001�q�K\u0001�q��h\u0002)Rq�tq�Rq�X'\u0000\u0000\u0000enc.model.3.model.2.model.0.conv.weightq�h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094301127168864q�X\u0006\u0000\u0000\u0000cuda:0q�J\u0000\u0000\t\u0000Ntq�QK\u0000(M\u0000\u0001M\u0000\u0001K\u0003K\u0003tq�(M\u0000\tK\tK\u0003K\u0001tq��h\u0002)Rq�tq�Rq�X%\u0000\u0000\u0000enc.model.3.model.2.model.0.conv.biasq�h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300125006736q�X\u0006\u0000\u0000\u0000cuda:0q�M\u0000\u0001Ntq�QK\u0000M\u0000\u0001�q�K\u0001�q��h\u0002)Rq�tq�Rq�X'\u0000\u0000\u0000enc.model.3.model.2.model.1.conv.weightq�h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300125006832q�X\u0006\u0000\u0000\u0000cuda:0q�J\u0000\u0000\t\u0000Ntq�QK\u0000(M\u0000\u0001M\u0000\u0001K\u0003K\u0003tq�(M\u0000\tK\tK\u0003K\u0001tq��h\u0002)Rq�tq�Rq�X%\u0000\u0000\u0000enc.model.3.model.2.model.1.conv.biasq�h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300125009456q�X\u0006\u0000\u0000\u0000cuda:0q�M\u0000\u0001Ntq�QK\u0000M\u0000\u0001�q�K\u0001�q��h\u0002)Rq�tq�Rq�X'\u0000\u0000\u0000enc.model.3.model.3.model.0.conv.weightq�h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300125011280q�X\u0006\u0000\u0000\u0000cuda:0q�J\u0000\u0000\t\u0000Ntq�QK\u0000(M\u0000\u0001M\u0000\u0001K\u0003K\u0003tq�(M\u0000\tK\tK\u0003K\u0001tq��h\u0002)Rq�tq�Rq�X%\u0000\u0000\u0000enc.model.3.model.3.model.0.conv.biasq�h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300125012096q�X\u0006\u0000\u0000\u0000cuda:0q�M\u0000\u0001Ntq�QK\u0000M\u0000\u0001�q�K\u0001�q��h\u0002)Rq�tq�Rq�X'\u0000\u0000\u0000enc.model.3.model.3.model.1.conv.weightq�h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300125013872q�X\u0006\u0000\u0000\u0000cuda:0q�J\u0000\u0000\t\u0000Ntq�QK\u0000(M\u0000\u0001M\u0000\u0001K\u0003K\u0003tq�(M\u0000\tK\tK\u0003K\u0001tq��h\u0002)Rq�tq�Rq�X%\u0000\u0000\u0000enc.model.3.model.3.model.1.conv.biasq�h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300125014640q�X\u0006\u0000\u0000\u0000cuda:0q�M\u0000\u0001Ntq�QK\u0000M\u0000\u0001�q�K\u0001�qɉh\u0002)Rq�tq�Rq�X'\u0000\u0000\u0000dec.model.0.model.0.model.0.conv.weightq�h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300125016464q�X\u0006\u0000\u0000\u0000cuda:0q�J\u0000\u0000\t\u0000Ntq�QK\u0000(M\u0000\u0001M\u0000\u0001K\u0003K\u0003tq�(M\u0000\tK\tK\u0003K\u0001tq҉h\u0002)Rq�tq�Rq�X%\u0000\u0000\u0000dec.model.0.model.0.model.0.conv.biasq�h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300125017280q�X\u0006\u0000\u0000\u0000cuda:0q�M\u0000\u0001Ntq�QK\u0000M\u0000\u0001�q�K\u0001�qۉh\u0002)Rq�tq�Rq�X'\u0000\u0000\u0000dec.model.0.model.0.model.1.conv.weightq�h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300125017744q�X\u0006\u0000\u0000\u0000cuda:0q�J\u0000\u0000\t\u0000Ntq�QK\u0000(M\u0000\u0001M\u0000\u0001K\u0003K\u0003tq�(M\u0000\tK\tK\u0003K\u0001tq�h\u0002)Rq�tq�Rq�X%\u0000\u0000\u0000dec.model.0.model.0.model.1.conv.biasq�h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300125020464q�X\u0006\u0000\u0000\u0000cuda:0q�M\u0000\u0001Ntq�QK\u0000M\u0000\u0001�q�K\u0001�q�h\u0002)Rq�tq�Rq�X'\u0000\u0000\u0000dec.model.0.model.1.model.0.conv.weightq�h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300125022288q�X\u0006\u0000\u0000\u0000cuda:0q�J\u0000\u0000\t\u0000Ntq�QK\u0000(M\u0000\u0001M\u0000\u0001K\u0003K\u0003tq�(M\u0000\tK\tK\u0003K\u0001tq��h\u0002)Rq�tq�Rq�X%\u0000\u0000\u0000dec.model.0.model.1.model.0.conv.biasq�h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094301127167888q�X\u0006\u0000\u0000\u0000cuda:0q�M\u0000\u0001Ntq�QK\u0000M\u0000\u0001�q�K\u0001�q��h\u0002)Rr\u0000\u0001\u0000\u0000tr\u0001\u0001\u0000\u0000Rr\u0002\u0001\u0000\u0000X'\u0000\u0000\u0000dec.model.0.model.1.model.1.conv.weightr\u0003\u0001\u0000\u0000h\u0005((h\u0006h\u0007X\u000e\u0000\u0000\u000094300125023056r\u0004\u0001\u0000\u0000X\u0006\u0000\u0000\u0000cuda:0r\u0005\u0001\u0000\u0000J\u0000\u0000\t\u0000Ntr\u0006\u0001\u0000\u0000QK\u0000(M\u0000\u0001M\u0000\u0001K\u0003K\u0003tr\u0007\u0001\u0000\u0000(M\u0000\tK\tK\u0003K\u0001t\u0001\u0000\u0000�h\u0002)Rr\t\u0001\u0000\u0000tr\n"
     ]
    }
   ],
   "source": [
    "!head /home/dfulu/model_outputs/outputs/hadgem3_to_cam5_nat-hist-v6/checkpoints/gen_00110000.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_n = '00110000'\n",
    "args = argsob()\n",
    "args.config = '/home/dfulu//repos/climateTranslation/climatetranslation/unit/configs/hadgem3_to_cam5_nat-hist-v6.yaml'\n",
    "args.checkpoint = f'/home/dfulu/model_outputs/outputs/hadgem3_to_cam5_nat-hist-v6/checkpoints/gen_{model_n}.pt'\n",
    "args.x2x = 'b2a'\n",
    "args.seed=1\n",
    "\n",
    "ds_translated_v6, da_prepost = get_translation(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_n = '00069000'\n",
    "args = argsob()\n",
    "args.config = '/home/dfulu//repos/climateTranslation/climatetranslation/unit/configs/hadgem3_to_cam5_nat-hist-v5.yaml'\n",
    "args.checkpoint = f'/home/dfulu/model_outputs/outputs/hadgem3_to_cam5_nat-hist-v5/checkpoints/gen_{model_n}.pt'\n",
    "args.x2x = 'b2a'\n",
    "args.seed=1\n",
    "\n",
    "ds_translated_v5, da_prepost = get_translation(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_translated_v6 = ds_translated_v6.mean(dim='time', keepdims=True)\n",
    "#ds_translated_v5 = ds_translated_v5.mean(dim='time', keepdims=True)\n",
    "#da_prepost = da_prepost.mean(dim='time', keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot2(0, var='tasmax',  lat=slice(-90, 90), lon=slice(0, 360))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot2(10, lat=slice(-90, 90), lon=slice(None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn=10\n",
    "\n",
    "tmin = float(ds_translated.isel(time=tn).tas.min())\n",
    "tmax = float(ds_translated.isel(time=tn).tas.max())\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "ds_translated.isel(time=tn).sel(lat=slice(-90, 90)).tas.plot(vmin=tmin, vmax=tmax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn=10\n",
    "\n",
    "tmin = min(float(ds_sample_regrid.isel(time=tn).tas.min()), float(ds_translated.isel(time=tn).tas.min()))\n",
    "tmax = max(float(ds_sample_regrid.isel(time=tn).tas.max()), float(ds_translated.isel(time=tn).tas.max()))\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.subplot(121)\n",
    "ds_sample_regrid.isel(time=tn).tas.plot(vmin=tmin, vmax=tmax)\n",
    "plt.title(\"regridded sample\")\n",
    "plt.subplot(122)\n",
    "ds_translated.isel(time=tn).tas.plot(vmin=tmin, vmax=tmax)\n",
    "plt.title(\"translated sample\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = 0\n",
    "pmin = min(float(ds_sample_regrid.isel(time=tn).pr.min()), float(ds_translated.isel(time=tn).pr.min()))\n",
    "pmax = max(float(ds_sample_regrid.isel(time=tn).pr.max()), float(ds_translated.isel(time=tn).pr.max()))\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.subplot(121)\n",
    "ds_sample_regrid.isel(time=tn).pr.plot(vmin=pmin, vmax=pmax)\n",
    "plt.subplot(122)\n",
    "ds_translated.isel(time=tn).pr.plot(vmin=pmin, vmax=pmax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = 0\n",
    "\n",
    "p4min = min(float(da_pre.isel(time=tn, variable=0).min()), float(da_post.isel(time=tn, variable=0).min()))\n",
    "p4max = max(float(da_pre.isel(time=tn, variable=0).max()), float(da_post.isel(time=tn, variable=0).max()))\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.subplot(121)\n",
    "da_pre.isel(time=tn, variable=tn).plot(vmin=p4min, vmax=p4max)\n",
    "plt.subplot(122)\n",
    "da_post.isel(time=tn, variable=tn).plot(vmin=p4min, vmax=p4max)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_sample_regrid.tas-ds_translated.tas).isel(time=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(da_list, **kwargs):\n",
    "    hv_list = []\n",
    "    for da in da_list:\n",
    "        hv_ds = hv.Dataset(da)\n",
    "        hv_list.append(hv_ds.to(hv.Image, ['lon', 'lat']).options(**kwargs))\n",
    "    return hv_list\n",
    "\n",
    "def animate_compare(da_a, da_b, name_a=None, name_b=None):\n",
    "        \n",
    "    images1 = get_images(\n",
    "        [da_a, da_b], \n",
    "        height=180,\n",
    "        width=360,\n",
    "        cmap='viridis',\n",
    "        colorbar=True\n",
    "    )\n",
    "    \n",
    "    # colorbars are matched if the variables have the same names\n",
    "    images2 = get_images(\n",
    "        [(da_a - da_b).rename('diff')], \n",
    "        height=180,\n",
    "        width=360,\n",
    "        cmap='bwr',\n",
    "        colorbar=True\n",
    "    )\n",
    "    \n",
    "    name_a = 'a' if name_a is None else name_a\n",
    "    name_b = 'b' if name_b is None else name_b\n",
    "    \n",
    "    vmax = max(abs(float((da_a - da_b).min())), abs(float((da_a - da_b).min())))\n",
    "    vmin = -vmax\n",
    "    \n",
    "\n",
    "    image  = images1[0].opts(title=name_a) \\\n",
    "           + images1[1].opts(title=name_b) \\\n",
    "           + images2[0].opts(title=f\"{name_a} - {name_b}\").redim.range(diff=(vmin, vmax))\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "image = animate_compare(ds_sample_regrid.isel(time=slice(0, 30)).tas, \n",
    "                        ds_translated.isel(time=slice(0, 30)).tas, \n",
    "                        'original', \n",
    "                        'translated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output holomap='scrubber'\n",
    "# ['gif', ]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = animate_compare(ds_sample_regrid.isel(time=slice(0, 30)).pr, \n",
    "                        ds_translated.isel(time=slice(0, 30)).pr, \n",
    "                        'original', \n",
    "                        'translated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output holomap='scrubber'\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = animate_compare(da_pre.isel(time=slice(0, 30), variable=0),\n",
    "                        da_post.isel(time=slice(0, 30), variable=0),\n",
    "                        'original', \n",
    "                        'translated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output holomap='scrubber'\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch2",
   "language": "python",
   "name": "conda-env-py37_pytorch2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
